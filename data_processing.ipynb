{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preprocessing and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#all necessary imports\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fetching rides data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rides = pd.read_csv('data/cab_rides.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initial exploration of the rides dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type     time_stamp              destination  \\\n",
      "0      0.44     Lyft  1544952607890            North Station   \n",
      "1      0.44     Lyft  1543284023677            North Station   \n",
      "2      0.44     Lyft  1543366822198            North Station   \n",
      "3      0.44     Lyft  1543553582749            North Station   \n",
      "4      0.44     Lyft  1543463360223            North Station   \n",
      "5      0.44     Lyft  1545071112138            North Station   \n",
      "6      1.08     Lyft  1543208580200  Northeastern University   \n",
      "7      1.08     Lyft  1543780384677  Northeastern University   \n",
      "8      1.08     Lyft  1543818482645  Northeastern University   \n",
      "9      1.08     Lyft  1543315522249  Northeastern University   \n",
      "\n",
      "             source  price  surge_multiplier  \\\n",
      "0  Haymarket Square    5.0               1.0   \n",
      "1  Haymarket Square   11.0               1.0   \n",
      "2  Haymarket Square    7.0               1.0   \n",
      "3  Haymarket Square   26.0               1.0   \n",
      "4  Haymarket Square    9.0               1.0   \n",
      "5  Haymarket Square   16.5               1.0   \n",
      "6          Back Bay   10.5               1.0   \n",
      "7          Back Bay   16.5               1.0   \n",
      "8          Back Bay    3.0               1.0   \n",
      "9          Back Bay   27.5               1.0   \n",
      "\n",
      "                                     id    product_id          name  \n",
      "0  424553bb-7174-41ea-aeb4-fe06d4f4b9d7     lyft_line        Shared  \n",
      "1  4bd23055-6827-41c6-b23b-3c491f24e74d  lyft_premier           Lux  \n",
      "2  981a3613-77af-4620-a42a-0c0866077d1e          lyft          Lyft  \n",
      "3  c2d88af2-d278-4bfd-a8d0-29ca77cc5512   lyft_luxsuv  Lux Black XL  \n",
      "4  e0126e1f-8ca9-4f2e-82b3-50505a09db9a     lyft_plus       Lyft XL  \n",
      "5  f6f6d7e4-3e18-4922-a5f5-181cdd3fa6f2      lyft_lux     Lux Black  \n",
      "6  462816a3-820d-408b-8549-0b39e82f65ac     lyft_plus       Lyft XL  \n",
      "7  474d6376-bc59-4ec9-bf57-4e6d6faeb165      lyft_lux     Lux Black  \n",
      "8  4f9fee41-fde3-4767-bbf1-a00e108701fb     lyft_line        Shared  \n",
      "9  8612d909-98b8-4454-a093-30bd48de0cb3   lyft_luxsuv  Lux Black XL  \n"
     ]
    }
   ],
   "source": [
    "print(rides.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693071, 10)\n"
     ]
    }
   ],
   "source": [
    "print(rides.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 693071 entries, 0 to 693070\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   distance          693071 non-null  float64\n",
      " 1   cab_type          693071 non-null  object \n",
      " 2   time_stamp        693071 non-null  int64  \n",
      " 3   destination       693071 non-null  object \n",
      " 4   source            693071 non-null  object \n",
      " 5   price             637976 non-null  float64\n",
      " 6   surge_multiplier  693071 non-null  float64\n",
      " 7   id                693071 non-null  object \n",
      " 8   product_id        693071 non-null  object \n",
      " 9   name              693071 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 37.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rides.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            distance    time_stamp          price  surge_multiplier\n",
      "count  693071.000000  6.930710e+05  637976.000000     693071.000000\n",
      "mean        2.189430  1.544046e+12      16.545125          1.013870\n",
      "std         1.138937  6.891925e+08       9.324359          0.091641\n",
      "min         0.020000  1.543204e+12       2.500000          1.000000\n",
      "25%         1.280000  1.543444e+12       9.000000          1.000000\n",
      "50%         2.160000  1.543737e+12      13.500000          1.000000\n",
      "75%         2.920000  1.544828e+12      22.500000          1.000000\n",
      "max         7.860000  1.545161e+12      97.500000          3.000000\n"
     ]
    }
   ],
   "source": [
    "print(rides.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration of the rides dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temp                 location  clouds  pressure    rain  time_stamp  \\\n",
      "0  42.42                 Back Bay     1.0   1012.14  0.1228  1545003901   \n",
      "1  42.43              Beacon Hill     1.0   1012.15  0.1846  1545003901   \n",
      "2  42.50        Boston University     1.0   1012.15  0.1089  1545003901   \n",
      "3  42.11                   Fenway     1.0   1012.13  0.0969  1545003901   \n",
      "4  43.13       Financial District     1.0   1012.14  0.1786  1545003901   \n",
      "5  42.34         Haymarket Square     1.0   1012.15  0.2068  1545003901   \n",
      "6  42.36                North End     1.0   1012.15  0.2088  1545003901   \n",
      "7  42.21            North Station     1.0   1012.16  0.2069  1545003901   \n",
      "8  42.07  Northeastern University     1.0   1012.12  0.1020  1545003901   \n",
      "9  43.05            South Station     1.0   1012.12  0.1547  1545003901   \n",
      "\n",
      "   humidity   wind  \n",
      "0      0.77  11.25  \n",
      "1      0.76  11.32  \n",
      "2      0.76  11.07  \n",
      "3      0.77  11.09  \n",
      "4      0.75  11.49  \n",
      "5      0.77  11.49  \n",
      "6      0.77  11.46  \n",
      "7      0.77  11.37  \n",
      "8      0.78  11.28  \n",
      "9      0.75  11.58  \n"
     ]
    }
   ],
   "source": [
    "print(weather.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6276, 8)\n"
     ]
    }
   ],
   "source": [
    "print(weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6276 entries, 0 to 6275\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   temp        6276 non-null   float64\n",
      " 1   location    6276 non-null   object \n",
      " 2   clouds      6276 non-null   float64\n",
      " 3   pressure    6276 non-null   float64\n",
      " 4   rain        894 non-null    float64\n",
      " 5   time_stamp  6276 non-null   int64  \n",
      " 6   humidity    6276 non-null   float64\n",
      " 7   wind        6276 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 367.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(weather.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              temp       clouds     pressure        rain    time_stamp  \\\n",
      "count  6276.000000  6276.000000  6276.000000  894.000000  6.276000e+03   \n",
      "mean     39.090475     0.677777  1008.445209    0.057652  1.543857e+09   \n",
      "std       6.022055     0.314284    12.870775    0.100758  6.659340e+05   \n",
      "min      19.620000     0.000000   988.250000    0.000200  1.543204e+09   \n",
      "25%      36.077500     0.440000   997.747500    0.004900  1.543387e+09   \n",
      "50%      40.130000     0.780000  1007.660000    0.014850  1.543514e+09   \n",
      "75%      42.832500     0.970000  1018.480000    0.060925  1.544691e+09   \n",
      "max      55.410000     1.000000  1035.120000    0.780700  1.545159e+09   \n",
      "\n",
      "          humidity         wind  \n",
      "count  6276.000000  6276.000000  \n",
      "mean      0.763985     6.802812  \n",
      "std       0.127340     3.633466  \n",
      "min       0.450000     0.290000  \n",
      "25%       0.670000     3.517500  \n",
      "50%       0.760000     6.570000  \n",
      "75%       0.890000     9.920000  \n",
      "max       0.990000    18.180000  \n"
     ]
    }
   ],
   "source": [
    "print(weather.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Merging ride and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 98.8 MiB for an array with shape (1295103, 20) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-3a242ecb9648>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;31m#I'm making a range because weather data and rides data were created in different intervals (we want the weather timestamp closest to the ride timestamp)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0msql_query\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"SELECT * FROM rides INNER JOIN weather ON rides.source = weather.location WHERE time_stamp_round  <= (rides.time_stamp_secs +1800) AND time_stamp_round >= ( rides.time_stamp_secs-1800)\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[0mnew_combined\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqldf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msql_query\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlocals\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[0mnew_combined\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/combined.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;31m#This data might some duplicates because they way we are merging -> we need to remove them\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandasql\\sqldf.py\u001B[0m in \u001B[0;36msqldf\u001B[1;34m(query, env, db_uri)\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;33m>>\u001B[0m\u001B[1;33m>\u001B[0m \u001B[0msqldf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"select avg(x) from df;\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlocals\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m     \"\"\"\n\u001B[1;32m--> 156\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mPandaSQL\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdb_uri\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandasql\\sqldf.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, query, env)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_sql\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mDatabaseError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mex\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mPandaSQLException\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36mread_sql\u001B[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001B[0m\n\u001B[0;32m    519\u001B[0m         )\n\u001B[0;32m    520\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m         return pandas_sql.read_query(\n\u001B[0m\u001B[0;32m    522\u001B[0m             \u001B[0msql\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m             \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mindex_col\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36mread_query\u001B[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001B[0m\n\u001B[0;32m   1320\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1321\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetchall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1322\u001B[1;33m             frame = _wrap_result(\n\u001B[0m\u001B[0;32m   1323\u001B[0m                 \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1324\u001B[0m                 \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\sql.py\u001B[0m in \u001B[0;36m_wrap_result\u001B[1;34m(data, columns, index_col, coerce_float, parse_dates)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_wrap_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparse_dates\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[1;34m\"\"\"Wrap result set of query in a DataFrame.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 135\u001B[1;33m     \u001B[0mframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m     \u001B[0mframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_parse_date_columns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparse_dates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mfrom_records\u001B[1;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001B[0m\n\u001B[0;32m   1853\u001B[0m             \u001B[0marr_columns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1854\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1855\u001B[1;33m             \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr_columns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1856\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1857\u001B[0m             \u001B[0marr_columns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr_columns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    550\u001B[0m         \u001B[1;31m# last ditch effort\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    551\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 552\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_list_to_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    553\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_list_to_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    560\u001B[0m ) -> Tuple[List[Scalar], Union[Index, List[Axis]]]:\n\u001B[0;32m    561\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 562\u001B[1;33m         \u001B[0mcontent\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_object_array_tuples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    563\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    564\u001B[0m         \u001B[1;31m# list of lists\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.to_object_array_tuples\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 98.8 MiB for an array with shape (1295103, 20) and data type object"
     ]
    }
   ],
   "source": [
    "rides['time_stamp_secs'] = rides['time_stamp'].div(1000).round(-1) #turning into seconds from miliseconds\n",
    "rides['time_stamp_secs'] = rides['time_stamp_secs'].astype(int)\n",
    "weather['time_stamp_round'] = weather['time_stamp'].round(-1)\n",
    "#print(sorted(rides.time_stamp_secs.unique()))\n",
    "#print(sorted(weather.time_stamp_round.unique()))\n",
    "\n",
    "#failed attempts with pandas merge\n",
    "#combined_data =  rides.merge( weather,how='inner', left_on=[\"time_stamp_secs\", \"source\"], right_on=[\"time_stamp_round\", \"location\"])\n",
    "#combined_data2 =  rides.merge( weather,how='inner', left_on=\"time_stamp_secs\", right_on=\"time_stamp_round\")\n",
    "\n",
    "#I'm making a range because weather data and rides data were created in different intervals (we want the weather timestamp closest to the ride timestamp)\n",
    "sql_query = \"SELECT * FROM rides INNER JOIN weather ON rides.source = weather.location WHERE time_stamp_round  <= (rides.time_stamp_secs +1800) AND time_stamp_round >= ( rides.time_stamp_secs-1800)\"\n",
    "new_combined = ps.sqldf(sql_query, locals())\n",
    "new_combined.to_csv('data/combined.csv')\n",
    "#This data might some duplicates because they way we are merging -> we need to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.88 MiB for an array with shape (1295103,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-25-26f7f2b343cd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcombined_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/combined.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcombined_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#more rows than in rides, we have some duplicates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 610\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    611\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    466\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    467\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 468\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    469\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1055\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1056\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"nrows\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1057\u001B[1;33m         \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1058\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1059\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\a_sta\\onedrive - worcester polytechnic institute (wpi.edu)\\2020-21\\d\\ds 3010\\final project\\ds3010project\\new_venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   2059\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2060\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2061\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2062\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2063\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_first_chunk\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers._concatenate_chunks\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 9.88 MiB for an array with shape (1295103,) and data type float64"
     ]
    }
   ],
   "source": [
    "combined_data = pd.read_csv('data/combined.csv')\n",
    "print(combined_data.shape) #more rows than in rides, we have some duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data = combined_data.drop_duplicates(subset=['id'])\n",
    "print(cleaned_data.shape)\n",
    "cleaned_data.drop(cleaned_data[cleaned_data['price'].isnull()].index, inplace = True)\n",
    "print(cleaned_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv('data/cleaned.csv')\n",
    "\n",
    "#replacing cab type with numerical ( Uber === 1, Lyft == 2 )\n",
    "cleaned_data['cab_type'].replace(['Uber'], 1, inplace=True)\n",
    "cleaned_data['cab_type'].replace(['Lyft'], 2, inplace=True)\n",
    "\n",
    "conditions = [\n",
    "    (cleaned_data.name == \"Shared\") | (cleaned_data.name == \"UberPool\" ),\n",
    "    (cleaned_data.product_id == \"lyft\") | (cleaned_data.name == \"UberX\"),\n",
    "    (cleaned_data.product_id == \"lyft_plus\") | (cleaned_data.name == \"UberXL\"),\n",
    "    (cleaned_data.product_id == \"lyft_premier\") | (cleaned_data.product_id == \"lyft_lux\") | (cleaned_data.product_id == \"lyft_luxsuv\") | (cleaned_data.name == \"Black\") | (cleaned_data.name == \"Black SUV\")\n",
    "]\n",
    "\n",
    "values = [1, 2, 3, 4] # 1 = shared rides, 2 = normal rides, 3 = XL rides, 4 = luxury rides, 0 = else (WAV)\n",
    "cleaned_data['ride_class'] = np.select(conditions, values)\n",
    "\n",
    "cleaned_data['ride_time'] = pd.to_datetime(cleaned_data.time_stamp_round, unit='s')\n",
    "#cleaned_data['ride_time'] = cleaned_data['ride_time'].dt.time\n",
    "cleaned_data['ride_time_mins'] = cleaned_data['ride_time'].dt.hour*60 + cleaned_data['ride_time'].dt.minute\n",
    "\n",
    "cleaned_data.to_csv('data/cleaned.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rides = pd.read_csv(\"data/cab_rides.csv\")\n",
    "cleaned_data = pd.read_csv(\"data/cleaned.csv\")\n",
    "combined_data = pd.read_csv('data/combined.csv')\n",
    "\n",
    "plt.hist(cleaned_data['price'], color = 'blue', edgecolor = 'black',\n",
    "         bins = int(180/5))\n",
    "\n",
    "sns.distplot(cleaned_data['price'], hist=True, kde=False,\n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "plt.title('Distribution of price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Number of rides')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(rides['price'], color = 'blue', edgecolor = 'black',\n",
    "         bins = int(180/5))\n",
    "\n",
    "sns.distplot(rides['price'], hist=True, kde=False,\n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "plt.title('Distribution of price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Number of rides')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lyft_line' 'lyft_premier' 'lyft' 'lyft_luxsuv' 'lyft_plus' 'lyft_lux'\n",
      " '6f72dfc5-27f1-42e8-84db-ccc7a75f6969'\n",
      " '6c84fd89-3f11-4782-9b50-97c468b19529'\n",
      " '55c66225-fbe7-4fd5-9072-eab1ece5e23e'\n",
      " '9a0e7b09-b92b-4c41-9779-2ad22b4d779d'\n",
      " '6d318bcc-22a3-4af6-bddd-b409bfce1546'\n",
      " '997acbb5-e102-41e1-b155-9df7de0a73f2']\n",
      "['Shared' 'Lux' 'Lyft' 'Lux Black XL' 'Lyft XL' 'Lux Black' 'UberXL'\n",
      " 'Black' 'UberX' 'WAV' 'Black SUV' 'UberPool']\n",
      "[2 1]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_data.product_id.unique())\n",
    "print(cleaned_data.name.unique())\n",
    "print(cleaned_data.cab_type.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}